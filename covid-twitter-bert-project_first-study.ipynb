{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12669603,"sourceType":"datasetVersion","datasetId":8006443}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch import nn, optim\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n\nimport optuna\nimport wandb\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-05T21:01:46.649489Z","iopub.execute_input":"2025-08-05T21:01:46.649751Z","iopub.status.idle":"2025-08-05T21:01:58.666653Z","shell.execute_reply.started":"2025-08-05T21:01:46.649730Z","shell.execute_reply":"2025-08-05T21:01:58.666014Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"wandb.login(key=\"d12da696b882ebdf6b786d182d46febc1a77dcdb\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T21:02:03.166053Z","iopub.execute_input":"2025-08-05T21:02:03.166342Z","iopub.status.idle":"2025-08-05T21:02:09.318535Z","shell.execute_reply.started":"2025-08-05T21:02:03.166320Z","shell.execute_reply":"2025-08-05T21:02:09.317956Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdiab55\u001b[0m (\u001b[33mdiab55-tel-aviv-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# טען את הקובץ המעובד\ndf = pd.read_csv(\"/kaggle/input/train-data1/processed_train.csv\")\n\n# שנה את שם עמודת הטקסט\ndf = df.rename(columns={'fully_clean_text': 'Tweet'})\n\n# קידוד התוויות ממחרוזות למספרים\nlabel_encoder = LabelEncoder()\ndf['label'] = label_encoder.fit_transform(df['Sentiment'])\n\n# שמור את המיפוי לצורך פיענוח בעתיד (אופציונלי)\nfor i, label in enumerate(label_encoder.classes_):\n    print(f\"{i} → {label}\")\n\n# חלוקה ל־Train / Test / Eval\ntrain_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['label'])\ntest_df, eval_df = train_test_split(temp_df, test_size=1/3, random_state=42, stratify=temp_df['label'])\n\n# שמירה של רק העמודות הדרושות למודל\ntrain_df = train_df[['Tweet', 'label']]\ntest_df = test_df[['Tweet', 'label']]\neval_df = eval_df[['Tweet', 'label']]\n\n# שמור את הקבצים החדשים\ntrain_df.to_csv('train_data.csv', index=False)\ntest_df.to_csv('test_data.csv', index=False)\neval_df.to_csv('eval_data.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T21:02:23.206536Z","iopub.execute_input":"2025-08-05T21:02:23.206811Z","iopub.status.idle":"2025-08-05T21:02:23.562168Z","shell.execute_reply.started":"2025-08-05T21:02:23.206791Z","shell.execute_reply":"2025-08-05T21:02:23.561398Z"}},"outputs":[{"name":"stdout","text":"0 → Extremely Negative\n1 → Extremely Positive\n2 → Negative\n3 → Neutral\n4 → Positive\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification  # transformers = HF\n\n# נטען את CT-BERT ממאגר HuggingFace\nmodel_name = \"digitalepidemiologylab/covid-twitter-bert\"\n\n# נטען את המודל עם מספר תוויות מתאים (5 – בהתאם ל־Sentiment שלך)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5).to(device)\nmodel  # הצגת מבנה המודל\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T21:02:33.017841Z","iopub.execute_input":"2025-08-05T21:02:33.018430Z","iopub.status.idle":"2025-08-05T21:03:06.914305Z","shell.execute_reply.started":"2025-08-05T21:02:33.018407Z","shell.execute_reply":"2025-08-05T21:03:06.913352Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/421 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"684adec524da4c0ea981131fe22961af"}},"metadata":{}},{"name":"stderr","text":"2025-08-05 21:02:45.355610: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754427765.602308      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754427765.666931      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.35G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da0854ecefbf48f0b8cc9dcc93f0d32c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1980c37c4b3415395ca964268ff831f"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n      (position_embeddings): Embedding(512, 1024)\n      (token_type_embeddings): Embedding(2, 1024)\n      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=1024, out_features=5, bias=True)\n)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"class TweetDataset(Dataset):\n    def __init__(self, dataframe, tokenizer):\n        self.texts = dataframe['Tweet'].tolist()\n        self.labels = dataframe['label'].tolist() \n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]  # כבר int\n\n        encoding = self.tokenizer(\n            text,\n            padding='max_length',\n            truncation=True,\n            max_length=100,\n            return_tensors='pt'\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].squeeze(),\n            'attention_mask': encoding['attention_mask'].squeeze(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T21:03:15.433263Z","iopub.execute_input":"2025-08-05T21:03:15.433880Z","iopub.status.idle":"2025-08-05T21:03:15.439424Z","shell.execute_reply.started":"2025-08-05T21:03:15.433853Z","shell.execute_reply":"2025-08-05T21:03:15.438804Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def early_stop_check(patience, best_val_accuracy, best_val_accuracy_epoch, current_val_accuracy, current_val_accuracy_epoch):\n    early_stop_flag = False\n    if current_val_accuracy > best_val_accuracy:\n        best_val_accuracy = current_val_accuracy\n        best_val_accuracy_epoch = current_val_accuracy_epoch\n    else:\n        if current_val_accuracy_epoch - best_val_accuracy_epoch > patience:\n            early_stop_flag = True\n    return best_val_accuracy, best_val_accuracy_epoch, early_stop_flag","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T21:03:21.109972Z","iopub.execute_input":"2025-08-05T21:03:21.110254Z","iopub.status.idle":"2025-08-05T21:03:21.114538Z","shell.execute_reply.started":"2025-08-05T21:03:21.110233Z","shell.execute_reply":"2025-08-05T21:03:21.113905Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport torch\n\n# ודא שיש לך את העמודה 'label' על בסיס 'Sentiment'\nlabel_encoder = LabelEncoder()\ndf['label'] = label_encoder.fit_transform(df['Sentiment'])\n\n# חישוב משקלי תוויות לפי הופעה בפועל\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(df['label']),\n    y=df['label']\n)\n\n# הפיכה לטנסור לשימוש בתוך CrossEntropyLoss\nclass_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n\n# יצירת פונקציית הפסד הכוללת משקלים\ncriterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T21:03:25.124751Z","iopub.execute_input":"2025-08-05T21:03:25.125489Z","iopub.status.idle":"2025-08-05T21:03:25.142488Z","shell.execute_reply.started":"2025-08-05T21:03:25.125462Z","shell.execute_reply":"2025-08-05T21:03:25.141767Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def train_model_with_hyperparams(model, train_loader, val_loader, optimizer, criterion, epochs, patience, trial):\n    best_val_accuracy = 0.0\n    best_val_accuracy_epoch = 0\n    early_stop_flag = False\n    best_model_state = None\n\n    for epoch in range(1, epochs + 1):\n        model.train()\n        train_loss = 0.0\n        total_train_samples = 0\n        correct_train_predictions = 0\n\n        for batch in train_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            optimizer.zero_grad()\n            outputs = model(input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            loss = criterion(logits, labels)\n\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item() * input_ids.size(0)\n            total_train_samples += input_ids.size(0)\n            correct_train_predictions += (logits.argmax(dim=1) == labels).sum().item()\n\n        train_loss /= total_train_samples\n        train_accuracy = correct_train_predictions / total_train_samples\n\n        ### Validation ###\n        model.eval()\n        val_loss = 0.0\n        total_val_samples = 0\n        correct_val_predictions = 0\n        all_val_labels = []\n        all_val_preds = []\n\n        with torch.no_grad():\n            for batch in val_loader:\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['labels'].to(device)\n\n                outputs = model(input_ids, attention_mask=attention_mask)\n                logits = outputs.logits\n                loss = criterion(logits, labels)\n\n                val_loss += loss.item() * input_ids.size(0)\n                total_val_samples += input_ids.size(0)\n                correct_val_predictions += (logits.argmax(dim=1) == labels).sum().item()\n\n                all_val_labels.extend(labels.cpu().numpy())\n                all_val_preds.extend(logits.argmax(dim=1).cpu().numpy())\n\n        val_loss /= total_val_samples\n        val_accuracy = correct_val_predictions / total_val_samples\n\n        # כאן שינוי חשוב: multi-class = average='weighted'\n        val_precision = precision_score(all_val_labels, all_val_preds, average='weighted', zero_division=0)\n        val_recall = recall_score(all_val_labels, all_val_preds, average='weighted', zero_division=0)\n        val_f1 = f1_score(all_val_labels, all_val_preds, average='weighted', zero_division=0)\n\n        best_val_accuracy, best_val_accuracy_epoch, early_stop_flag = early_stop_check(\n            patience, best_val_accuracy, best_val_accuracy_epoch, val_accuracy, epoch)\n\n        if val_accuracy == best_val_accuracy:\n            best_model_state = model.state_dict()\n\n        wandb.log({\n            \"Epoch\": epoch,\n            \"Train Loss\": train_loss,\n            \"Train Accuracy\": train_accuracy,\n            \"Validation Loss\": val_loss,\n            \"Validation Accuracy\": val_accuracy,\n            \"Validation Precision\": val_precision,\n            \"Validation Recall\": val_recall,\n            \"Validation F1\": val_f1\n        })\n\n        if early_stop_flag:\n            break\n\n    if best_model_state is not None:\n        torch.save(best_model_state, f\"best_model_trial_{trial.number}.pt\")\n\n    return best_val_accuracy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T21:03:28.957714Z","iopub.execute_input":"2025-08-05T21:03:28.958585Z","iopub.status.idle":"2025-08-05T21:03:28.969219Z","shell.execute_reply.started":"2025-08-05T21:03:28.958549Z","shell.execute_reply":"2025-08-05T21:03:28.968479Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Objective Function for Optuna\ndef objective(trial):\n    # === Hyperparameter suggestions ===\n    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True)\n    patience = trial.suggest_int(\"patience\", 2, 5)\n    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n\n    # === Tokenizer and Dataset ===\n    tokenizer = AutoTokenizer.from_pretrained(\"digitalepidemiologylab/covid-twitter-bert\")\n\n    train_dataset = TweetDataset(train_df, tokenizer)\n    val_dataset = TweetDataset(eval_df, tokenizer)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n    # === Load CT-BERT Model ===\n    model = AutoModelForSequenceClassification.from_pretrained(\n        \"digitalepidemiologylab/covid-twitter-bert\", num_labels=5\n    ).to(device)\n\n    # === Freeze all layers first ===\n    for param in model.bert.parameters():\n        param.requires_grad = False\n\n    # === Unfreeze the last `num_layers` of encoder ===\n    for param in model.bert.encoder.layer[-num_layers:].parameters():\n        param.requires_grad = True\n\n    # === Unfreeze the classification head ===\n    for param in model.classifier.parameters():\n        param.requires_grad = True\n\n    # === Define loss with class weights ===\n    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n\n    # === Optimizer ===\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n\n    # === Initialize W&B for tracking ===\n    wandb.init(\n        project=\"ctbert-project\",\n        config={\n            \"learning_rate\": learning_rate,\n            \"weight_decay\": weight_decay,\n            \"patience\": patience,\n            \"batch_size\": batch_size,\n            \"num_layers\": num_layers,\n            \"architecture\": \"CT-BERT\",\n            \"dataset\": \"covid-tweets\"\n        },\n        name=f\"trial_{trial.number}\"\n    )\n\n    # === Train and evaluate ===\n    best_val_accuracy = train_model_with_hyperparams(\n        model, train_loader, val_loader, optimizer, criterion, epochs=10,\n        patience=patience, trial=trial\n    )\n\n    wandb.finish()\n    return best_val_accuracy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T21:03:34.149647Z","iopub.execute_input":"2025-08-05T21:03:34.150132Z","iopub.status.idle":"2025-08-05T21:03:35.156962Z","shell.execute_reply.started":"2025-08-05T21:03:34.150108Z","shell.execute_reply":"2025-08-05T21:03:35.156215Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Optuna Study\nstudy = optuna.create_study(direction=\"maximize\")  # אנו מעוניינים למקסם את ה-Validation Accuracy\nstudy.optimize(objective, n_trials=10)  # הפעלת 10 ניסויים","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T21:03:39.316489Z","iopub.execute_input":"2025-08-05T21:03:39.317006Z"}},"outputs":[{"name":"stderr","text":"[I 2025-08-05 21:03:39,318] A new study created in memory with name: no-name-03ec4ab9-b7f0-4ebc-96a2-5e54792918c7\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7f0e8325eaf4823b1068c2e448cc5a8"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250805_210343-9zhj7f5k</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/9zhj7f5k' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/9zhj7f5k' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/9zhj7f5k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▆▆▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▆▆▇▇▇▇██</td></tr><tr><td>Validation F1</td><td>▁▅▆▇▇▇▇▇██</td></tr><tr><td>Validation Loss</td><td>█▄▂▂▁▁▁▂▂▂</td></tr><tr><td>Validation Precision</td><td>▁▄▆▇▇▇▇▇██</td></tr><tr><td>Validation Recall</td><td>▁▄▆▆▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.79969</td></tr><tr><td>Train Loss</td><td>0.47467</td></tr><tr><td>Validation Accuracy</td><td>0.651</td></tr><tr><td>Validation F1</td><td>0.64865</td></tr><tr><td>Validation Loss</td><td>0.91224</td></tr><tr><td>Validation Precision</td><td>0.64946</td></tr><tr><td>Validation Recall</td><td>0.651</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/9zhj7f5k' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/9zhj7f5k</a><br> View project at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250805_210343-9zhj7f5k/logs</code>"},"metadata":{}},{"name":"stderr","text":"[I 2025-08-05 22:10:23,284] Trial 0 finished with value: 0.6512420847540185 and parameters: {'learning_rate': 1.0650532870197462e-05, 'weight_decay': 8.174075923922814e-05, 'patience': 5, 'batch_size': 64, 'num_layers': 3}. Best is trial 0 with value: 0.6512420847540185.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250805_221026-6wq8mcn8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/6wq8mcn8' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/6wq8mcn8' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/6wq8mcn8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▅▆▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▂▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▆▇▇▇▇███</td></tr><tr><td>Validation F1</td><td>▁▄▆▇▇▇▇███</td></tr><tr><td>Validation Loss</td><td>▄▂▁▂▂▄▄▆██</td></tr><tr><td>Validation Precision</td><td>▁▄▆▇▇█████</td></tr><tr><td>Validation Recall</td><td>▁▄▆▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.92401</td></tr><tr><td>Train Loss</td><td>0.19203</td></tr><tr><td>Validation Accuracy</td><td>0.69532</td></tr><tr><td>Validation F1</td><td>0.695</td></tr><tr><td>Validation Loss</td><td>1.05739</td></tr><tr><td>Validation Precision</td><td>0.69591</td></tr><tr><td>Validation Recall</td><td>0.69532</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/6wq8mcn8' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/6wq8mcn8</a><br> View project at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250805_221026-6wq8mcn8/logs</code>"},"metadata":{}},{"name":"stderr","text":"[I 2025-08-05 23:13:47,043] Trial 1 finished with value: 0.701656113005358 and parameters: {'learning_rate': 0.0001385418354078171, 'weight_decay': 3.5608825471932415e-05, 'patience': 5, 'batch_size': 32, 'num_layers': 2}. Best is trial 1 with value: 0.701656113005358.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250805_231352-wxwjan2r</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/wxwjan2r' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/wxwjan2r' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/wxwjan2r</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▅▆▆▇▇██</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▅▆▆▇▇███</td></tr><tr><td>Validation F1</td><td>▁▂▄▆▆▇▇███</td></tr><tr><td>Validation Loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▃▅▆▆▇▇███</td></tr><tr><td>Validation Recall</td><td>▁▃▅▆▆▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.64173</td></tr><tr><td>Train Loss</td><td>0.81235</td></tr><tr><td>Validation Accuracy</td><td>0.57306</td></tr><tr><td>Validation F1</td><td>0.56133</td></tr><tr><td>Validation Loss</td><td>0.93192</td></tr><tr><td>Validation Precision</td><td>0.57546</td></tr><tr><td>Validation Recall</td><td>0.57306</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/wxwjan2r' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/wxwjan2r</a><br> View project at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250805_231352-wxwjan2r/logs</code>"},"metadata":{}},{"name":"stderr","text":"[I 2025-08-06 00:12:54,768] Trial 2 finished with value: 0.5769605455431076 and parameters: {'learning_rate': 1.2827057681926272e-05, 'weight_decay': 3.3196061780734544e-06, 'patience': 5, 'batch_size': 32, 'num_layers': 1}. Best is trial 1 with value: 0.701656113005358.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250806_001258-1o7q1n26</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/1o7q1n26' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/1o7q1n26' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/1o7q1n26</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▄▅▆▆▇▇██</td></tr><tr><td>Train Loss</td><td>█▅▅▄▃▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▃▁▆▆▅▆▇▅▇█</td></tr><tr><td>Validation F1</td><td>▅▁▇▆▆▇▇▅▇█</td></tr><tr><td>Validation Loss</td><td>▇█▂▄▅▃▁▃▃▄</td></tr><tr><td>Validation Precision</td><td>▄▁▅▄▇▆▇▅▇█</td></tr><tr><td>Validation Recall</td><td>▃▁▆▆▅▆▇▅▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.73787</td></tr><tr><td>Train Loss</td><td>0.61458</td></tr><tr><td>Validation Accuracy</td><td>0.63371</td></tr><tr><td>Validation F1</td><td>0.63553</td></tr><tr><td>Validation Loss</td><td>0.98941</td></tr><tr><td>Validation Precision</td><td>0.6427</td></tr><tr><td>Validation Recall</td><td>0.63371</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/1o7q1n26' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/1o7q1n26</a><br> View project at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250806_001258-1o7q1n26/logs</code>"},"metadata":{}},{"name":"stderr","text":"[I 2025-08-06 01:15:34,948] Trial 3 finished with value: 0.6337067705796395 and parameters: {'learning_rate': 0.0008639822228096007, 'weight_decay': 8.518065042137753e-06, 'patience': 3, 'batch_size': 64, 'num_layers': 2}. Best is trial 1 with value: 0.701656113005358.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250806_011539-xqwuhni5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/xqwuhni5' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/xqwuhni5' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/xqwuhni5</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▄▅▅▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▅▆▇▇█</td></tr><tr><td>Train Loss</td><td>█▆▅▅▄▃▃▂▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▇▆▇█▇██</td></tr><tr><td>Validation F1</td><td>▁▅▇▆▇█▇██</td></tr><tr><td>Validation Loss</td><td>█▄▂▂▁▁▄▅▇</td></tr><tr><td>Validation Precision</td><td>▁▄▇▆▇█▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▅▇▆▇█▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>9</td></tr><tr><td>Train Accuracy</td><td>0.81142</td></tr><tr><td>Train Loss</td><td>0.43995</td></tr><tr><td>Validation Accuracy</td><td>0.60692</td></tr><tr><td>Validation F1</td><td>0.6038</td></tr><tr><td>Validation Loss</td><td>1.06646</td></tr><tr><td>Validation Precision</td><td>0.60797</td></tr><tr><td>Validation Recall</td><td>0.60692</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/xqwuhni5' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/xqwuhni5</a><br> View project at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250806_011539-xqwuhni5/logs</code>"},"metadata":{}},{"name":"stderr","text":"[I 2025-08-06 02:08:18,709] Trial 4 finished with value: 0.6117876278616659 and parameters: {'learning_rate': 6.175153396025764e-05, 'weight_decay': 3.1474423114844143e-06, 'patience': 2, 'batch_size': 64, 'num_layers': 1}. Best is trial 1 with value: 0.701656113005358.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250806_020822-xtq5p2eg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/xtq5p2eg' target=\"_blank\">trial_5</a></strong> to <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/xtq5p2eg' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/xtq5p2eg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▄▅▆▆▇██</td></tr><tr><td>Train Loss</td><td>█▆▆▅▄▃▃▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▃▆▄█▆█▅▇</td></tr><tr><td>Validation F1</td><td>▁▁▂▅▃█▆█▅▇</td></tr><tr><td>Validation Loss</td><td>▃▂▂▁▁▃▄▆██</td></tr><tr><td>Validation Precision</td><td>▁▂▄▆▃█▆█▅▆</td></tr><tr><td>Validation Recall</td><td>▁▂▃▆▄█▆█▅▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.88028</td></tr><tr><td>Train Loss</td><td>0.29237</td></tr><tr><td>Validation Accuracy</td><td>0.61763</td></tr><tr><td>Validation F1</td><td>0.616</td></tr><tr><td>Validation Loss</td><td>1.22754</td></tr><tr><td>Validation Precision</td><td>0.6163</td></tr><tr><td>Validation Recall</td><td>0.61763</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_5</strong> at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/xtq5p2eg' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/xtq5p2eg</a><br> View project at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250806_020822-xtq5p2eg/logs</code>"},"metadata":{}},{"name":"stderr","text":"[I 2025-08-06 03:06:51,784] Trial 5 finished with value: 0.626643935703848 and parameters: {'learning_rate': 0.00015201411443589258, 'weight_decay': 1.983657271648714e-06, 'patience': 3, 'batch_size': 64, 'num_layers': 1}. Best is trial 1 with value: 0.701656113005358.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250806_030655-8f8wi7k6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/8f8wi7k6' target=\"_blank\">trial_6</a></strong> to <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/8f8wi7k6' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/8f8wi7k6</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▆▆▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▆▆▇▇█▇██</td></tr><tr><td>Validation F1</td><td>▁▄▆▆▇▇█▇██</td></tr><tr><td>Validation Loss</td><td>█▄▂▂▁▁▁▁▃▃</td></tr><tr><td>Validation Precision</td><td>▁▄▆▆▇▇█▇██</td></tr><tr><td>Validation Recall</td><td>▁▄▆▆▇▇█▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.82116</td></tr><tr><td>Train Loss</td><td>0.42144</td></tr><tr><td>Validation Accuracy</td><td>0.66585</td></tr><tr><td>Validation F1</td><td>0.66406</td></tr><tr><td>Validation Loss</td><td>0.90945</td></tr><tr><td>Validation Precision</td><td>0.6652</td></tr><tr><td>Validation Recall</td><td>0.66585</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_6</strong> at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/8f8wi7k6' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/8f8wi7k6</a><br> View project at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250806_030655-8f8wi7k6/logs</code>"},"metadata":{}},{"name":"stderr","text":"[I 2025-08-06 04:09:32,106] Trial 6 finished with value: 0.665854846566001 and parameters: {'learning_rate': 1.955683912476931e-05, 'weight_decay': 1.6290992478902544e-06, 'patience': 5, 'batch_size': 64, 'num_layers': 2}. Best is trial 1 with value: 0.701656113005358.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250806_040935-fq57enfz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/fq57enfz' target=\"_blank\">trial_7</a></strong> to <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/fq57enfz' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/fq57enfz</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇██</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▃█▇▆▃</td></tr><tr><td>Validation F1</td><td>▂▂▁█▇▆▂</td></tr><tr><td>Validation Loss</td><td>█▃▃▁▃▃▅</td></tr><tr><td>Validation Precision</td><td>▁▄███▇▅</td></tr><tr><td>Validation Recall</td><td>▁▃▃█▇▆▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>7</td></tr><tr><td>Train Accuracy</td><td>0.68996</td></tr><tr><td>Train Loss</td><td>0.7045</td></tr><tr><td>Validation Accuracy</td><td>0.59523</td></tr><tr><td>Validation F1</td><td>0.58351</td></tr><tr><td>Validation Loss</td><td>0.93715</td></tr><tr><td>Validation Precision</td><td>0.61232</td></tr><tr><td>Validation Recall</td><td>0.59523</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_7</strong> at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/fq57enfz' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/fq57enfz</a><br> View project at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250806_040935-fq57enfz/logs</code>"},"metadata":{}},{"name":"stderr","text":"[I 2025-08-06 04:50:35,142] Trial 7 finished with value: 0.6310277642474428 and parameters: {'learning_rate': 0.00041522673002310846, 'weight_decay': 3.485129578494981e-06, 'patience': 2, 'batch_size': 64, 'num_layers': 1}. Best is trial 1 with value: 0.701656113005358.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250806_045038-ilqww431</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/ilqww431' target=\"_blank\">trial_8</a></strong> to <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/ilqww431' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/ilqww431</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▆▆▇▇███</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▇▆▇▇▇███</td></tr><tr><td>Validation F1</td><td>▁▅▇▆▇▇▇███</td></tr><tr><td>Validation Loss</td><td>▃▁▁▂▃▃▆▆▆█</td></tr><tr><td>Validation Precision</td><td>▁▄▇▅▇▇▇███</td></tr><tr><td>Validation Recall</td><td>▁▅▇▆▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.94266</td></tr><tr><td>Train Loss</td><td>0.14846</td></tr><tr><td>Validation Accuracy</td><td>0.70604</td></tr><tr><td>Validation F1</td><td>0.70774</td></tr><tr><td>Validation Loss</td><td>1.20498</td></tr><tr><td>Validation Precision</td><td>0.71231</td></tr><tr><td>Validation Recall</td><td>0.70604</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_8</strong> at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/ilqww431' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/ilqww431</a><br> View project at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250806_045038-ilqww431/logs</code>"},"metadata":{}},{"name":"stderr","text":"[I 2025-08-06 05:57:21,297] Trial 8 finished with value: 0.709206039941549 and parameters: {'learning_rate': 0.0001137639693455489, 'weight_decay': 6.499757184807477e-05, 'patience': 4, 'batch_size': 64, 'num_layers': 3}. Best is trial 8 with value: 0.709206039941549.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250806_055725-r47span3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/r47span3' target=\"_blank\">trial_9</a></strong> to <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/r47span3' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project/runs/r47span3</a>"},"metadata":{}}],"execution_count":null}]}